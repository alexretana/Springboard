{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hits': {'hits': [{'_score': 1.0, '_type': 'complaint', '_id': '3398126', '_source': {':created_at': 1575703677, 'sub_product': 'Mobile or digital wallet', 'date_sent_to_company': '2019-10-07T12:00:00-05:00', 'date_indexed_formatted': '12/16/19', 'complaint_id': '3398126', 'date_received_formatted': '10/07/19', ':updated_at': 1575703677, 'tags': None, 'state': 'PA', 'date_received': '2019-10-07T12:00:00-05:00', 'consumer_disputed': 'N/A', 'issue': 'Unauthorized transactions or other transaction problem', 'company_response': 'Closed with non-monetary relief', 'date_indexed': '2019-12-16T12:00:00-05:00', 'zip_code': '191XX', 'timely': 'Yes', 'product': 'Money transfer, virtual currency, or money service', 'complaint_what_happened': 'I was using Venmo, a PayPal company, to transfer {$180.00} into my bank account via their instant transfer option on XX/XX/XXXX at XXXX. I have contacted both my bank ( XXXX XXXX XXXX ) and Venmo numerous times. Both saying that the other is responsible for the money not being received into my account.', 'date_sent_to_company_formatted': '10/07/19', 'company': 'PAYPAL HOLDINGS INC.', 'sub_issue': None, 'consumer_consent_provided': 'Consent provided', 'company_public_response': None, 'has_narrative': True, 'submitted_via': 'Web'}, '_index': 'complaint-public-v2'}], 'total': 1, 'max_score': 1.0}, '_shards': {'successful': 5, 'failed': 0, 'total': 5}, 'took': 3, 'timed_out': False}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "resp = requests.get('https://www.consumerfinance.gov/data-research/consumer-complaints/search/api/v1/3398126')\n",
    "if resp.status_code != 200:\n",
    "    # This means something went wrong.\n",
    "    raise ApiError('GET /tasks/ {}'.format(resp.status_code))\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{':created_at': 1575703677,\n",
       " 'sub_product': 'Mobile or digital wallet',\n",
       " 'date_sent_to_company': '2019-10-07T12:00:00-05:00',\n",
       " 'date_indexed_formatted': '12/16/19',\n",
       " 'complaint_id': '3398126',\n",
       " 'date_received_formatted': '10/07/19',\n",
       " ':updated_at': 1575703677,\n",
       " 'tags': None,\n",
       " 'state': 'PA',\n",
       " 'date_received': '2019-10-07T12:00:00-05:00',\n",
       " 'consumer_disputed': 'N/A',\n",
       " 'issue': 'Unauthorized transactions or other transaction problem',\n",
       " 'company_response': 'Closed with non-monetary relief',\n",
       " 'date_indexed': '2019-12-16T12:00:00-05:00',\n",
       " 'zip_code': '191XX',\n",
       " 'timely': 'Yes',\n",
       " 'product': 'Money transfer, virtual currency, or money service',\n",
       " 'complaint_what_happened': 'I was using Venmo, a PayPal company, to transfer {$180.00} into my bank account via their instant transfer option on XX/XX/XXXX at XXXX. I have contacted both my bank ( XXXX XXXX XXXX ) and Venmo numerous times. Both saying that the other is responsible for the money not being received into my account.',\n",
       " 'date_sent_to_company_formatted': '10/07/19',\n",
       " 'company': 'PAYPAL HOLDINGS INC.',\n",
       " 'sub_issue': None,\n",
       " 'consumer_consent_provided': 'Consent provided',\n",
       " 'company_public_response': None,\n",
       " 'has_narrative': True,\n",
       " 'submitted_via': 'Web'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()['hits']['hits'][0]['_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=1, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-2627bbdc1a88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdropList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Company response to consumer\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;31m#Columns to be standard scaled/imputed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2098\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2099\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[1;32m-> 2100\u001b[1;33m                                               default_test_size=0.25)\n\u001b[0m\u001b[0;32m   2101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   1780\u001b[0m             \u001b[1;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1781\u001b[0m             'aforementioned parameters.'.format(n_samples, test_size,\n\u001b[1;32m-> 1782\u001b[1;33m                                                 train_size)\n\u001b[0m\u001b[0;32m   1783\u001b[0m         )\n\u001b[0;32m   1784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=1, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "#Gets complaint Id from request\n",
    "complaint_id = int(resp.json()['hits']['hits'][0]['_source']['complaint_id'])\n",
    "\n",
    "#Creates DataFrame from REST API\n",
    "df1 = pd.DataFrame(resp.json()['hits']['hits'][0]['_source'], index=[complaint_id])\n",
    "\n",
    "#generate drop list for before preprocessing\n",
    "droplist1 = [':created_at',\n",
    "             'date_indexed_formatted',\n",
    "             'complaint_id',\n",
    "             'date_received_formatted',\n",
    "             ':updated_at',\n",
    "             'date_indexed',\n",
    "             'date_sent_to_company_formatted',\n",
    "             'has_narrative']\n",
    "#drop columns\n",
    "df_drop1 = df1.drop(droplist1,axis=1)\n",
    "\n",
    "#list that corrects names to agree with preprocessor's accepted name\n",
    "corrected_cols= ['Sub-product',\n",
    "                 'Date sent to company',\n",
    "                 'Tags',\n",
    "                 'State',\n",
    "                 'Date received',\n",
    "                 'Consumer disputed?',\n",
    "                 'Issue',\n",
    "                 'Company response to consumer',\n",
    "                 'ZIP code',\n",
    "                 'Timely response?',\n",
    "                 'Product',\n",
    "                 'Consumer complaint narrative',\n",
    "                 'Company',\n",
    "                 'Sub-issue',\n",
    "                 'Consumer consent provided?',\n",
    "                 'Company public response',\n",
    "                 'Submitted via']\n",
    "\n",
    "#rename columns\n",
    "df_drop1.columns = corrected_cols\n",
    "\n",
    "#match order of columns. Generated with list(df.columns.values) from other notebooks\n",
    "reordered_cols= ['Date received',\n",
    "                 'Product',\n",
    "                 'Sub-product',\n",
    "                 'Issue',\n",
    "                 'Sub-issue',\n",
    "                 'Consumer complaint narrative',\n",
    "                 'Company public response',\n",
    "                 'Company',\n",
    "                 'State',\n",
    "                 'ZIP code',\n",
    "                 'Tags',\n",
    "                 'Consumer consent provided?',\n",
    "                 'Submitted via',\n",
    "                 'Date sent to company',\n",
    "                 'Company response to consumer',\n",
    "                 'Timely response?',\n",
    "                 'Consumer disputed?']\n",
    "#actually reorderes columns\n",
    "df_reordered = df_drop1[reordered_cols]\n",
    "\n",
    "#set index name to match\n",
    "df_reordered.index.name='Complaint ID'\n",
    "\n",
    "#define dictionary to define new dtypes\n",
    "dtype_dict = {'Product':\"category\",\n",
    "             'Consumer consent provided?': \"category\",\n",
    "             'Submitted via': \"category\",\n",
    "             'Consumer disputed?': \"category\",\n",
    "             'Date received':'<M8[ns]',\n",
    "             'Date sent to company':'<M8[ns]'}\n",
    "\n",
    "#change dtypes\n",
    "df = df_reordered.astype(dtype_dict)\n",
    "\n",
    "#use old code to transfrom data\n",
    "\n",
    "#This will replace ending '-' to 5 (average linespace of 10)\n",
    "regexReplaceDash = r\"(\\d+)(-)$\"\n",
    "df['ZIP code'] = df['ZIP code'].str.replace(regexReplaceDash, r'\\g<1>5')\n",
    "\n",
    "#This will change ending XX to 50 (average linespace of 100)\n",
    "regex_XX = r'(\\d{3})(XX)'\n",
    "df['ZIP code'] = df['ZIP code'].str.replace(regex_XX, r'\\g<1>50')\n",
    "\n",
    "#This will remove all other entries that are still not 5 digits\n",
    "regexRemove = r'\\D+'\n",
    "df['ZIP code'] = df['ZIP code'].replace(regexRemove, np.nan, regex=True)\n",
    "\n",
    "#imputes the mean for nan \n",
    "imputeMean = df['ZIP code'].astype(np.float).mean()\n",
    "df['ZIP code'] = df['ZIP code'].astype(np.float).fillna(imputeMean)\n",
    "\n",
    "#Transforming 2 unique valued col to float boolean\n",
    "booleanize = {'Yes': 1, 'No': 0}\n",
    "df['Timely response?'] = pd.Series(df['Timely response?'].map(booleanize), dtype = np.float)\n",
    "\n",
    "#function to apply to column to convert less common results to 'Other', as well as NaN\n",
    "def convertToOther(value, keepList):\n",
    "    if (value == ''):\n",
    "        return \"Other\"\n",
    "    else:\n",
    "        return value if value in keepList else \"Other\"\n",
    "    \n",
    "#Lists top 23 value counts (allowed to exclude values), turns NaN to '' to others, converts to category dtype\n",
    "def cleanReduceConvert(df, column, blackList=[]):\n",
    "    keepList = []\n",
    "    for category in df[column].value_counts().head(23).index.tolist():\n",
    "        if (category.lower().split()[0] != \"other\"):\n",
    "            keepList.append(category)\n",
    "    for category in blackList:\n",
    "        try:\n",
    "            keepList.remove(category)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    df[column].fillna('', inplace=True)\n",
    "    return pd.Series(df[column].apply(convertToOther, args=(keepList,)), dtype = 'category')\n",
    "\n",
    "df['Sub-product'] = cleanReduceConvert(df, 'Sub-product', blackList= ['I do not know'])\n",
    "df['Issue'] = cleanReduceConvert(df, 'Issue')\n",
    "df['Sub-issue'] = cleanReduceConvert(df, 'Sub-issue')\n",
    "df['Company'] = cleanReduceConvert(df, 'Company')\n",
    "\n",
    "def entryOrNull(strVal):\n",
    "    return 1.0 if strVal is not np.nan else 0.0\n",
    "\n",
    "df['Consumer complaint narrative submitted?'] = df['Consumer complaint narrative'].apply(entryOrNull)\n",
    "\n",
    "def dtToCols(df, dtcolumn):\n",
    "    df[\"{} day\".format(dtcolumn)] = df[dtcolumn].dt.day\n",
    "    df[\"{} month\".format(dtcolumn)] = df[dtcolumn].dt.month\n",
    "    df[\"{} year\".format(dtcolumn)] = df[dtcolumn].dt.year\n",
    "    \n",
    "dtToCols(df, \"Date received\")\n",
    "dtToCols(df, \"Date sent to company\")\n",
    "\n",
    "df[\"Consumer consent provided?\"] = df[\"Consumer consent provided?\"].cat.add_categories(\"Not recorded\").fillna(\"Not recorded\")\n",
    "\n",
    "df = df.drop(df[df[\"Company response to consumer\"].isna()].index)\n",
    "\n",
    "dfInProgress = df[df[\"Company response to consumer\"] == \"In progress\"]\n",
    "df = df[df[\"Company response to consumer\"] != \"In progress\"]\n",
    "\n",
    "dfUntimelyResponse = df[df[\"Company response to consumer\"] == \"Untimely response\"]\n",
    "df = df[df[\"Company response to consumer\"] != \"Untimely response\"]\n",
    "\n",
    "twoOutputsDict = {\"Closed with explanation\":\"Closed without relief\", \n",
    "                  \"Closed with non-monetary relief\":\"Closed with relief\",\n",
    "                  \"Closed with monetary relief\":\"Closed with relief\",\n",
    "                  \"Closed without relief\":\"Closed without relief\", \n",
    "                  \"Closed\":\"Closed without relief\",\n",
    "                  \"Closed with relief\":\"Closed with relief\"}\n",
    "df[\"Company response to consumer\"] = df[\"Company response to consumer\"].map(twoOutputsDict)\n",
    "\n",
    "\n",
    "#data columns not be used for the model\n",
    "dropList = [\"Consumer complaint narrative\",\n",
    "            \"Company public response\",\n",
    "            \"State\",\n",
    "            \"Tags\",\n",
    "            \"Consumer disputed?\",\n",
    "            \"Date received\", \n",
    "            \"Date sent to company\",\n",
    "            \"Company response to consumer\"]\n",
    "X = df.drop(dropList, axis=1)\n",
    "Y = df[\"Company response to consumer\"]\n",
    "\n",
    "#Columns to be standard scaled/imputed\n",
    "numeric_features = ['ZIP code',\n",
    "                    'Date received day',\n",
    "                    'Date received month',\n",
    "                    'Date received year',\n",
    "                    'Date sent to company day',\n",
    "                    'Date sent to company month',\n",
    "                    'Date sent to company year']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "#Columns to one hot encoded\n",
    "categorical_features = ['Product',\n",
    "           'Sub-product',\n",
    "           'Issue',\n",
    "           'Sub-issue',\n",
    "           'Company',\n",
    "           'Consumer consent provided?',\n",
    "           'Submitted via',\n",
    "           'Timely response?']\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "#building the column transformer with both transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "#fit the preprocessor, then transform trainging and test set, assign sparse matrix to variables\n",
    "preprocessor.fit(X)\n",
    "encX_train = preprocessor.transform(X_train)\n",
    "encX_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Change up this code below to save models and load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "scaler_filename = \"scaler.save\"\n",
    "joblib.dump(scaler, scaler_filename) \n",
    "\n",
    "# And now to load...\n",
    "\n",
    "scaler = joblib.load(scaler_filename) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
