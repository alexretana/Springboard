{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing the Production Code\n",
    "\n",
    "In this final notebook, the code that will be pushed to production will be developed. Although there will be a file to train and a file to load and predict, both will be developed and tested here.\n",
    "\n",
    "First thing to test is a code to make an REST API call to the Consumer Financial Complaint Bureau's API to fetch an entry based on a complaint ID. The requests library is used for making the api request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hits': {'hits': [{'_score': 1.0, '_type': 'complaint', '_id': '3398126', '_source': {':created_at': 1575703677, 'sub_product': 'Mobile or digital wallet', 'date_sent_to_company': '2019-10-07T12:00:00-05:00', 'date_indexed_formatted': '12/16/19', 'complaint_id': '3398126', 'date_received_formatted': '10/07/19', ':updated_at': 1575703677, 'tags': None, 'state': 'PA', 'date_received': '2019-10-07T12:00:00-05:00', 'consumer_disputed': 'N/A', 'issue': 'Unauthorized transactions or other transaction problem', 'company_response': 'Closed with non-monetary relief', 'date_indexed': '2019-12-16T12:00:00-05:00', 'zip_code': '191XX', 'timely': 'Yes', 'product': 'Money transfer, virtual currency, or money service', 'complaint_what_happened': 'I was using Venmo, a PayPal company, to transfer {$180.00} into my bank account via their instant transfer option on XX/XX/XXXX at XXXX. I have contacted both my bank ( XXXX XXXX XXXX ) and Venmo numerous times. Both saying that the other is responsible for the money not being received into my account.', 'date_sent_to_company_formatted': '10/07/19', 'company': 'PAYPAL HOLDINGS INC.', 'sub_issue': None, 'consumer_consent_provided': 'Consent provided', 'company_public_response': None, 'has_narrative': True, 'submitted_via': 'Web'}, '_index': 'complaint-public-v2'}], 'total': 1, 'max_score': 1.0}, '_shards': {'successful': 5, 'failed': 0, 'total': 5}, 'took': 3, 'timed_out': False}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "resp = requests.get('https://www.consumerfinance.gov/data-research/consumer-complaints/search/api/v1/3398126')\n",
    "if resp.status_code != 200:\n",
    "    # This means something went wrong.\n",
    "    raise ApiError('GET /tasks/ {}'.format(resp.status_code))\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, the response from the request is printed to screen. After exploring the json a bit, the data entry is found using the indexing below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{':created_at': 1575703677,\n",
       " 'sub_product': 'Mobile or digital wallet',\n",
       " 'date_sent_to_company': '2019-10-07T12:00:00-05:00',\n",
       " 'date_indexed_formatted': '12/16/19',\n",
       " 'complaint_id': '3398126',\n",
       " 'date_received_formatted': '10/07/19',\n",
       " ':updated_at': 1575703677,\n",
       " 'tags': None,\n",
       " 'state': 'PA',\n",
       " 'date_received': '2019-10-07T12:00:00-05:00',\n",
       " 'consumer_disputed': 'N/A',\n",
       " 'issue': 'Unauthorized transactions or other transaction problem',\n",
       " 'company_response': 'Closed with non-monetary relief',\n",
       " 'date_indexed': '2019-12-16T12:00:00-05:00',\n",
       " 'zip_code': '191XX',\n",
       " 'timely': 'Yes',\n",
       " 'product': 'Money transfer, virtual currency, or money service',\n",
       " 'complaint_what_happened': 'I was using Venmo, a PayPal company, to transfer {$180.00} into my bank account via their instant transfer option on XX/XX/XXXX at XXXX. I have contacted both my bank ( XXXX XXXX XXXX ) and Venmo numerous times. Both saying that the other is responsible for the money not being received into my account.',\n",
       " 'date_sent_to_company_formatted': '10/07/19',\n",
       " 'company': 'PAYPAL HOLDINGS INC.',\n",
       " 'sub_issue': None,\n",
       " 'consumer_consent_provided': 'Consent provided',\n",
       " 'company_public_response': None,\n",
       " 'has_narrative': True,\n",
       " 'submitted_via': 'Web'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()['hits']['hits'][0]['_source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrainSaveModel.py\n",
    "\n",
    "In the next cell, a cleaned up version of the code to train the logistic regression is displayed and run. The model and preprocessor are then linked with a pipeline, and then saved using joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexr\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\alexr\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n",
      "C:\\Users\\alexr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed with these results: \n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "   Closed with relief       0.32      0.66      0.43     78895\n",
      "Closed without relief       0.89      0.68      0.77    337985\n",
      "\n",
      "             accuracy                           0.68    416880\n",
      "            macro avg       0.61      0.67      0.60    416880\n",
      "         weighted avg       0.79      0.68      0.71    416880\n",
      "\n",
      "Model has been saved to : lrmodelpipeline.save\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "#Defining what dtype to convert each column to\n",
    "#numberic columns are transformed after reading in\n",
    "dtype_dict = {'Product':\"category\",\n",
    "             'Consumer consent provided?': \"category\",\n",
    "             'Submitted via': \"category\",\n",
    "             'Company response to consumer': \"category\",\n",
    "             'Consumer disputed?': \"category\"}\n",
    "\n",
    "#read in .csv file, dates are parsed into datetime objects. \n",
    "#The Complaint ID is Unique in every entry, so it can be used as index\n",
    "df = pd.read_csv('../Consumer_Complaints.csv',\n",
    "                 index_col=['Complaint ID'],\n",
    "                 parse_dates=[\"Date received\",\"Date sent to company\"],\n",
    "                 dtype=dtype_dict)\n",
    "\n",
    "#This will replace ending '-' to 5 (average linespace of 10)\n",
    "regexReplaceDash = r\"(\\d+)(-)$\"\n",
    "df['ZIP code'] = df['ZIP code'].str.replace(regexReplaceDash, r'\\g<1>5')\n",
    "\n",
    "#This will change ending XX to 50 (average linespace of 100)\n",
    "regex_XX = r'(\\d{3})(XX)'\n",
    "df['ZIP code'] = df['ZIP code'].str.replace(regex_XX, r'\\g<1>50')\n",
    "\n",
    "#This will remove all other entries that are still not 5 digits\n",
    "regexRemove = r'\\D+'\n",
    "df['ZIP code'] = df['ZIP code'].replace(regexRemove, np.nan, regex=True)\n",
    "\n",
    "#imputes the mean for nan \n",
    "imputeMean = df['ZIP code'].astype(np.float).mean()\n",
    "df['ZIP code'] = df['ZIP code'].astype(np.float).fillna(imputeMean)\n",
    "\n",
    "#Transforming 2 unique valued col to float boolean\n",
    "booleanize = {'Yes': 1, 'No': 0}\n",
    "df['Timely response?'] = pd.Series(df['Timely response?'].map(booleanize), dtype = np.float)\n",
    "\n",
    "#function to apply to column to convert less common results to 'Other', as well as NaN\n",
    "def convertToOther(value, keepList):\n",
    "    if (value == ''):\n",
    "        return \"Other\"\n",
    "    else:\n",
    "        return value if value in keepList else \"Other\"\n",
    "    \n",
    "#Lists top 23 value counts (allowed to exclude values), turns NaN to '' to others, converts to category dtype\n",
    "def cleanReduceConvert(df, column, blackList=[]):\n",
    "    keepList = []\n",
    "    for category in df[column].value_counts().head(23).index.tolist():\n",
    "        if (category.lower().split()[0] != \"other\"):\n",
    "            keepList.append(category)\n",
    "    for category in blackList:\n",
    "        try:\n",
    "            keepList.remove(category)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    df[column].fillna('', inplace=True)\n",
    "    return pd.Series(df[column].apply(convertToOther, args=(keepList,)), dtype = 'category')\n",
    "\n",
    "df['Sub-product'] = cleanReduceConvert(df, 'Sub-product', blackList= ['I do not know'])\n",
    "df['Issue'] = cleanReduceConvert(df, 'Issue')\n",
    "df['Sub-issue'] = cleanReduceConvert(df, 'Sub-issue')\n",
    "df['Company'] = cleanReduceConvert(df, 'Company')\n",
    "\n",
    "def entryOrNull(strVal):\n",
    "    return 1.0 if strVal is not np.nan else 0.0\n",
    "\n",
    "df['Consumer complaint narrative submitted?'] = df['Consumer complaint narrative'].apply(entryOrNull)\n",
    "\n",
    "def dtToCols(df, dtcolumn):\n",
    "    df[\"{} day\".format(dtcolumn)] = df[dtcolumn].dt.day\n",
    "    df[\"{} month\".format(dtcolumn)] = df[dtcolumn].dt.month\n",
    "    df[\"{} year\".format(dtcolumn)] = df[dtcolumn].dt.year\n",
    "    \n",
    "dtToCols(df, \"Date received\")\n",
    "dtToCols(df, \"Date sent to company\")\n",
    "\n",
    "df[\"Consumer consent provided?\"] = df[\"Consumer consent provided?\"].cat.add_categories(\"Not recorded\").fillna(\"Not recorded\")\n",
    "\n",
    "df = df.drop(df[df[\"Company response to consumer\"].isna()].index)\n",
    "\n",
    "dfInProgress = df[df[\"Company response to consumer\"] == \"In progress\"]\n",
    "df = df[df[\"Company response to consumer\"] != \"In progress\"]\n",
    "\n",
    "dfUntimelyResponse = df[df[\"Company response to consumer\"] == \"Untimely response\"]\n",
    "df = df[df[\"Company response to consumer\"] != \"Untimely response\"]\n",
    "\n",
    "twoOutputsDict = {\"Closed with explanation\":\"Closed without relief\", \n",
    "                  \"Closed with non-monetary relief\":\"Closed with relief\",\n",
    "                  \"Closed with monetary relief\":\"Closed with relief\",\n",
    "                  \"Closed without relief\":\"Closed without relief\", \n",
    "                  \"Closed\":\"Closed without relief\",\n",
    "                  \"Closed with relief\":\"Closed with relief\"}\n",
    "df[\"Company response to consumer\"] = df[\"Company response to consumer\"].map(twoOutputsDict)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "#data columns not be used for the model\n",
    "dropList = [\"Consumer complaint narrative\",\n",
    "            \"Company public response\",\n",
    "            \"State\",\n",
    "            \"Tags\",\n",
    "            \"Consumer disputed?\",\n",
    "            \"Date received\", \n",
    "            \"Date sent to company\",\n",
    "            \"Company response to consumer\"]\n",
    "X = df.drop(dropList, axis=1)\n",
    "Y = df[\"Company response to consumer\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "\n",
    "#Columns to be standard scaled/imputed\n",
    "numeric_features = ['ZIP code',\n",
    "                    'Date received day',\n",
    "                    'Date received month',\n",
    "                    'Date received year',\n",
    "                    'Date sent to company day',\n",
    "                    'Date sent to company month',\n",
    "                    'Date sent to company year']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "#Columns to one hot encoded\n",
    "categorical_features = ['Product',\n",
    "           'Sub-product',\n",
    "           'Issue',\n",
    "           'Sub-issue',\n",
    "           'Company',\n",
    "           'Consumer consent provided?',\n",
    "           'Submitted via',\n",
    "           'Timely response?']\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "#building the column transformer with both transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "#fit the preprocessor, then transform trainging and test set, assign sparse matrix to variables\n",
    "preprocessor.fit(X)\n",
    "encX_train = preprocessor.transform(X_train)\n",
    "encX_test = preprocessor.transform(X_test)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "lr = LogisticRegression(n_jobs=-1, solver='saga', penalty='l1')\n",
    "lr_para = {'C':[10,1.0,0.1,0.01], \n",
    "           'class_weight':[None,'balanced'],\n",
    "           'max_iter':[50,100,150]}\n",
    "\n",
    "#Apply grid search with above parameters specified\n",
    "fitmodel = GridSearchCV(lr, lr_para,cv=4, scoring='roc_auc', n_jobs=-1)\n",
    "fitmodel.fit(encX_train,y_train)\n",
    "\n",
    "#store the best fitting LogisiticRegression(), create prediciton from X_test data\n",
    "bestfitLR = fitmodel.best_estimator_\n",
    "y_pred = bestfitLR.predict(encX_test)\n",
    "print('Training Completed with these results: \\n')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('logregclassifier', bestfitLR)])\n",
    "\n",
    "\n",
    "\n",
    "import joblib\n",
    "pipeline_filename = \"lrmodelpipeline.save\"\n",
    "joblib.dump(clf, pipeline_filename) \n",
    "\n",
    "print('Model has been saved to :', pipeline_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoadModelPredict.py\n",
    "\n",
    "The code below starts by creating a data from response json, and reformats the columns to be able to be pushed into the pre-trained model. Since this is done only on one data entry, the prediction comes out 'instantly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, getopt\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def main(argv):\n",
    "    try:\n",
    "        opts, args = getopt.getopt(argv, \"hi:\", ['complaint='])\n",
    "    except getopt.GetoptError:\n",
    "        print  'LoadModelPredict.py -i <complaintID>'\n",
    "        sys.exit(2)\n",
    "    for opt, arg in opts:\n",
    "        if opt == 'h':\n",
    "            print 'LoadModelPredict.py -i <complaintID>'\n",
    "        elif opt in (\"-i\", \"--complaint\"):\n",
    "            complaintID = int(arg)\n",
    "    print('Complaint #', complaintID, \"'s outcome will be predicted:\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    apiurl = 'https://www.consumerfinance.gov/data-research/consumer-complaints/search/api/v1/'\n",
    "    queriedUrl = apiurl + str(complaintID)\n",
    "    resp = requests.get(queriedUrl)\n",
    "    if resp.status_code != 200:\n",
    "        # This means something went wrong.\n",
    "        print(\"ApiError: response status code\", resp.status_code)\n",
    "    if resp.json()['hits']['total'] == 0:\n",
    "        print(\"Complaint ID yielded 0 result. Check to make sure you inputed it correctly.\")\n",
    "        sys.exit()\n",
    "    ### Paste rest of code here\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of Outcome:  Closed without relief\n",
      "With a  39.31 % chance of being Closed with relief\n"
     ]
    }
   ],
   "source": [
    "import sys, getopt\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "resp = requests.get('https://www.consumerfinance.gov/data-research/consumer-complaints/search/api/v1/3398126')\n",
    "if resp.status_code != 200:\n",
    "    # This means something went wrong.\n",
    "    raise ApiError('GET /tasks/ {}'.format(resp.status_code))\n",
    "\n",
    "#Gets complaint Id from request\n",
    "complaint_id = int(resp.json()['hits']['hits'][0]['_source']['complaint_id'])\n",
    "\n",
    "#Creates DataFrame from REST API response\n",
    "df1 = pd.DataFrame(resp.json()['hits']['hits'][0]['_source'], index=[complaint_id])\n",
    "\n",
    "#generate drop list for before preprocessing\n",
    "droplist1 = ['date_indexed_formatted',\n",
    "             'complaint_id',\n",
    "             'date_received_formatted',\n",
    "             ':updated_at',\n",
    "             'date_indexed',\n",
    "             'date_sent_to_company_formatted',\n",
    "             'has_narrative']\n",
    "#drop columns\n",
    "df_drop1 = df1.drop(droplist1,axis=1)\n",
    "\n",
    "#list that corrects names to agree with preprocessor's accepted name\n",
    "corrected_cols_dict = {'tags':'Tags',\n",
    "                       'zip_code':'ZIP code',\n",
    "                       'issue':'Issue',\n",
    "                       'date_received':'Date received',\n",
    "                       'state':'State',\n",
    "                       'consumer_disputed':'Consumer disputed?',\n",
    "                       'product':'Product',\n",
    "                       'company_response':'Company response to consumer',\n",
    "                       'submitted_via':'Submitted via',\n",
    "                       'company':'Company',\n",
    "                       'date_sent_to_company':'Date sent to company',\n",
    "                       'company_public_response':'Company public response',\n",
    "                       'sub_product':'Sub-product',\n",
    "                       'timely':'Timely response?',\n",
    "                       'complaint_what_happened':'Consumer complaint narrative',\n",
    "                       'sub_issue':'Sub-issue',\n",
    "                       'consumer_consent_provided':'Consumer consent provided?'}\n",
    "\n",
    "df_drop1 = df_drop1.rename(corrected_cols_dict, axis=1)\n",
    "\n",
    "#match order of columns. Generated with list(df.columns.values) from other notebooks\n",
    "reordered_cols= ['Date received',\n",
    "                 'Product',\n",
    "                 'Sub-product',\n",
    "                 'Issue',\n",
    "                 'Sub-issue',\n",
    "                 'Consumer complaint narrative',\n",
    "                 'Company public response',\n",
    "                 'Company',\n",
    "                 'State',\n",
    "                 'ZIP code',\n",
    "                 'Tags',\n",
    "                 'Consumer consent provided?',\n",
    "                 'Submitted via',\n",
    "                 'Date sent to company',\n",
    "                 'Company response to consumer',\n",
    "                 'Timely response?',\n",
    "                 'Consumer disputed?']\n",
    "#actually reorderes columns\n",
    "df_reordered = df_drop1[reordered_cols]\n",
    "\n",
    "#set index name to match\n",
    "df_reordered.index.name='Complaint ID'\n",
    "\n",
    "#define dictionary to define new dtypes\n",
    "dtype_dict = {'Product':\"category\",\n",
    "             'Consumer consent provided?': \"category\",\n",
    "             'Submitted via': \"category\",\n",
    "             'Consumer disputed?': \"category\",\n",
    "             'Date received':'<M8[ns]',\n",
    "             'Date sent to company':'<M8[ns]'}\n",
    "\n",
    "#change dtypes\n",
    "df = df_reordered.astype(dtype_dict)\n",
    "\n",
    "#use old code to transfrom data\n",
    "\n",
    "#This will replace ending '-' to 5 (average linespace of 10)\n",
    "regexReplaceDash = r\"(\\d+)(-)$\"\n",
    "df['ZIP code'] = df['ZIP code'].str.replace(regexReplaceDash, r'\\g<1>5')\n",
    "\n",
    "#This will change ending XX to 50 (average linespace of 100)\n",
    "regex_XX = r'(\\d{3})(XX)'\n",
    "df['ZIP code'] = df['ZIP code'].str.replace(regex_XX, r'\\g<1>50')\n",
    "\n",
    "#This will remove all other entries that are still not 5 digits\n",
    "regexRemove = r'\\D+'\n",
    "df['ZIP code'] = df['ZIP code'].replace(regexRemove, np.nan, regex=True)\n",
    "\n",
    "#imputes the mean for nan \n",
    "imputeMean = df['ZIP code'].astype(np.float).mean()\n",
    "df['ZIP code'] = df['ZIP code'].astype(np.float).fillna(imputeMean)\n",
    "\n",
    "#Transforming 2 unique valued col to float boolean\n",
    "booleanize = {'Yes': 1, 'No': 0}\n",
    "df['Timely response?'] = pd.Series(df['Timely response?'].map(booleanize), dtype = np.float)\n",
    "\n",
    "#function to apply to column to convert less common results to 'Other', as well as NaN\n",
    "def convertToOther(value, keepList):\n",
    "    if (value == ''):\n",
    "        return \"Other\"\n",
    "    else:\n",
    "        return value if value in keepList else \"Other\"\n",
    "    \n",
    "#Lists top 23 value counts (allowed to exclude values), turns NaN to '' to others, converts to category dtype\n",
    "def cleanReduceConvert(df, column, blackList=[]):\n",
    "    keepList = []\n",
    "    for category in df[column].value_counts().head(23).index.tolist():\n",
    "        if (category.lower().split()[0] != \"other\"):\n",
    "            keepList.append(category)\n",
    "    for category in blackList:\n",
    "        try:\n",
    "            keepList.remove(category)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    df[column].fillna('', inplace=True)\n",
    "    return pd.Series(df[column].apply(convertToOther, args=(keepList,)), dtype = 'category')\n",
    "\n",
    "df['Sub-product'] = cleanReduceConvert(df, 'Sub-product', blackList= ['I do not know'])\n",
    "df['Issue'] = cleanReduceConvert(df, 'Issue')\n",
    "df['Sub-issue'] = cleanReduceConvert(df, 'Sub-issue')\n",
    "df['Company'] = cleanReduceConvert(df, 'Company')\n",
    "\n",
    "def entryOrNull(strVal):\n",
    "    return 1.0 if strVal is not np.nan else 0.0\n",
    "\n",
    "df['Consumer complaint narrative submitted?'] = df['Consumer complaint narrative'].apply(entryOrNull)\n",
    "\n",
    "def dtToCols(df, dtcolumn):\n",
    "    df[\"{} day\".format(dtcolumn)] = df[dtcolumn].dt.day\n",
    "    df[\"{} month\".format(dtcolumn)] = df[dtcolumn].dt.month\n",
    "    df[\"{} year\".format(dtcolumn)] = df[dtcolumn].dt.year\n",
    "    \n",
    "dtToCols(df, \"Date received\")\n",
    "dtToCols(df, \"Date sent to company\")\n",
    "\n",
    "df[\"Consumer consent provided?\"] = df[\"Consumer consent provided?\"].cat.add_categories(\"Not recorded\").fillna(\"Not recorded\")\n",
    "\n",
    "df = df.drop(df[df[\"Company response to consumer\"].isna()].index)\n",
    "\n",
    "dfInProgress = df[df[\"Company response to consumer\"] == \"In progress\"]\n",
    "df = df[df[\"Company response to consumer\"] != \"In progress\"]\n",
    "\n",
    "dfUntimelyResponse = df[df[\"Company response to consumer\"] == \"Untimely response\"]\n",
    "df = df[df[\"Company response to consumer\"] != \"Untimely response\"]\n",
    "\n",
    "twoOutputsDict = {\"Closed with explanation\":\"Closed without relief\", \n",
    "                  \"Closed with non-monetary relief\":\"Closed with relief\",\n",
    "                  \"Closed with monetary relief\":\"Closed with relief\",\n",
    "                  \"Closed without relief\":\"Closed without relief\", \n",
    "                  \"Closed\":\"Closed without relief\",\n",
    "                  \"Closed with relief\":\"Closed with relief\"}\n",
    "df[\"Company response to consumer\"] = df[\"Company response to consumer\"].map(twoOutputsDict)\n",
    "\n",
    "\n",
    "\n",
    "#data columns not be used for the model\n",
    "dropList = [\"Consumer complaint narrative\",\n",
    "            \"Company public response\",\n",
    "            \"State\",\n",
    "            \"Tags\",\n",
    "            \"Consumer disputed?\",\n",
    "            \"Date received\", \n",
    "            \"Date sent to company\",\n",
    "            \"Company response to consumer\"]\n",
    "X = df.drop(dropList, axis=1)\n",
    "Y = df[\"Company response to consumer\"]\n",
    "\n",
    "import joblib\n",
    "\n",
    "pipeline_filename = \"lrmodelpipeline.save\"\n",
    "\n",
    "loaded_clf = joblib.load(pipeline_filename)\n",
    "prediction = loaded_clf.predict(X)[0]\n",
    "pred_proba_perc = loaded_clf.predict_proba(X)[0][0] * 100\n",
    "\n",
    "print(\"For Complaint# \", complaintID)\n",
    "print(\"Prediction of Outcome: \", prediction)\n",
    "print(\"With a \", round(pred_proba_perc, 2) , \"% chance of being Closed with relief\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39312809675499716"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_clf.predict_proba(X)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'took': 3, 'timed_out': False, '_shards': {'total': 5, 'successful': 5, 'failed': 0}, 'hits': {'total': 1, 'max_score': 1.0, 'hits': [{'_index': 'complaint-public-v1', '_type': 'complaint', '_id': '3398126', '_score': 1.0, '_source': {'tags': None, 'date_indexed_formatted': '01/15/20', ':updated_at': 1579042205, 'date_indexed': '2020-01-15T12:00:00-05:00', 'zip_code': '191XX', 'complaint_id': '3398126', 'issue': 'Unauthorized transactions or other transaction problem', 'date_received': '2019-10-07T12:00:00-05:00', 'state': 'PA', 'date_sent_to_company_formatted': '10/07/19', 'date_received_formatted': '10/07/19', 'consumer_disputed': 'N/A', 'has_narrative': True, 'product': 'Money transfer, virtual currency, or money service', 'company_response': 'Closed with non-monetary relief', 'submitted_via': 'Web', 'company': 'Paypal Holdings, Inc', 'date_sent_to_company': '2019-10-07T12:00:00-05:00', 'company_public_response': None, 'sub_product': 'Mobile or digital wallet', 'timely': 'Yes', 'complaint_what_happened': 'I was using Venmo, a PayPal company, to transfer {$180.00} into my bank account via their instant transfer option on XX/XX/XXXX at XXXX. I have contacted both my bank ( XXXX XXXX XXXX ) and Venmo numerous times. Both saying that the other is responsible for the money not being received into my account.', 'sub_issue': None, 'consumer_consent_provided': 'Consent provided'}}]}}\n"
     ]
    }
   ],
   "source": [
    "complaintID = int(3398126)\n",
    "apiurl = 'https://www.consumerfinance.gov/data-research/consumer-complaints/search/api/v1/'\n",
    "queriedUrl = apiurl + str(complaintID)\n",
    "resp = requests.get(queriedUrl)\n",
    "if resp.status_code != 200:\n",
    "    # This means something went wrong.\n",
    "    raise ApiError('GET /tasks/ {}'.format(resp.status_code))\n",
    "if resp.json()['hits']['total'] == 0:\n",
    "    print(\"Complaint ID yielded 0 result. Check to make sure you inputed it correctly.\")\n",
    "    sys.exit()\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.status_code = 201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ApiError: response status code 201\n"
     ]
    }
   ],
   "source": [
    "if resp.status_code != 200:\n",
    "    # This means something went wrong.\n",
    "    print(\"ApiError: response status code\", resp.status_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
